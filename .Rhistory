15:1
?`:`
seq(1, 20)
seq(0, 10, by=0.5)
my_seq <- seq(5, 10, length=30)
length(my_seq)
1:length(my_seq)
seq(along.with = my_seq)
seq_along(my_seq)
rep(0, times=40)
rep(c(0, 1, 2), times = 10)
rep(c(0, 1, 2), each = 10)
num_vect <- c(0.5,55,-10,6)
tf <- num_vect < 1
tf
num_vect >= 6
my_char <- c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
my_name <- c(my_char, "Johnny")
my_name
paste(my_name, collapse = " ")
paste("Hello", "world!", sep = " ")
paste(c("X", "Y", "Z"), sep = " ")
paste(1:3, c("X", "Y", "Z"), sep = "")
paste(LETTERS, 1:4, sep = "-")
x <- c(44, NA, 5, NA)
x*3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y, z), 100)
my_na <- is.na(my_data)
my_na
my_data == NA
sum(my_na)
my_data
0/0
Inf-Inf
x
x[1:10]
x[is.na(x)]
y <- x[!is.na(x)]
y
y[y > 0]
x[x > 0]
x[!is.na(x) & x > 0]
x[c(3, 5, 7)]
x[0]
x[3000]
x[c(-2, -10)]
x[-c(2, 10)]
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2 <- c(11, 2, NA)
names(vect2) <- ("foo", "bar", "norf")
names(vect2) <- c("foo", "bar", "norf")
identical(vect, vect2)
vect["bar"]
vect[c("foo", "bar")]
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4, 5)
attributes(my_vector)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
my_matrix2 <- as.matrix(1:20)
my_matrix2 <- matrix(1:20, nrow = 4, ncol = 5, byrow = FALSE)
identical(my_matrix, my_matrix2)
patients <- c("Bill", "Gina", "Kelly", "Sean")
cbind(patients, my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class(my_data)
cnames <- c("patient", "age", "weight", "bp", "rating", "test")
colnames(my_data) <- cnames
my_data
TRUE == TRUE
(FALSE == TRUE) == FALSE
6 == 7
6 < 7
10 <= 10
5 != 7
!(5 == 7)
FALSE & FALSE
TRUE & c(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6 != 8 && 4 > 3.9
isTRUE(6 > 4)
identical('twins', 'twins')
xor(5 == 6, !FALSE)
ints <- sample(10)
ints
ints > 5
which(ints > 7)
any(ints < 0)
all(ints > 0)
Sys.Date()
mean(c(2, 5, 5))
mean(c(2, 4, 5))
submit()
submit()
boring_function('My first function!')
boring_function
x
}
boring_function
boring_function
function(x) {
x
}
boring_function
submit()
my_mean(c(4, 5, 10))
submit()
remainder(5)
submit()
submit()
my_mean(c(4, 5, 10))
submit()
submit()
remainder(5)
remainder(11, 5)
remainder(11, 5)
remainder(divisor = 11, num = 5)
remainder(4, div = 2)
args(remainder)
submit()
evaluate(sd, c(1.4, 3.6, 7.9, 8.8))
evaluate(function(x){x+1}, 6)
evaluate(function(x){x[1]}, c(8, 4, 0))
evaluate(function(x){x[-1]}, c(8, 4, 0))
evaluate(function(x){x[length(x)]}, c(8, 4, 0))
?paste
paste("Programming", "is", "fun!")
submit()
telegram(c("Hello", "world", ",", "how", "are", "we", "today", "?"))
telegram("Good", "morning")
elegram(c("Good", "morning"))
telegram(c("Good", "morning"))
nxt()
submit()
mad_libs(place = "London", adjustive = "beautiful", noun = "dog")
submit()
submit()
"I love R!"
"I" %p% "love" %p% "R!"
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags, class)
v
cls_list
class(cls_list)
as.character(cls_list)
?sapply
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[, 11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[, 19:23]
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3,4, 5, 5, 5, 6, 6))
unique_vals <- lapply(flags, unique)
unique_vals
unique_vals
sapply(unique_vals, length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags, unique)
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants, 10)
tail(plants, 15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6, 4, replace = TRUE)
sample(1:6, 4, replace = TRUE)
sample(1:20, 10)
LETTERS
sample(LETTERS)
sample(c(0, 1), 100, replace = TRUE, prob = c(0.3, 0.7))
flips
sample(c(0, 1), 100, replace = TRUE, prob = c(0.3, 0.7))
flips <- sample(c(0,1), 100, replace = TRUE, prob = c(0.3, 0.7))
flips
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(100, size = 1, prob = 0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
?rpois
rnorm(10, mean = 100, sd = 25)
?rpois
rpois(5, 10)
my_pois <- replicate(100, rpois(5, 10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
d2 <- as.Date("1969-01-01")
unclass(d2)
t1 <- Sys.time()
t1
class(t1)
unclass(t1)
t2 <- as.POSIXlt(Sys.time())
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(d1)
months(t1)
quarters(t2)
t3 <- "October 17, 1986 08:24"
t4 <- strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time() > t1
Sys.time() - t1
difftime(Sys.time(), t1, units = "days")
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x = cars$speed, y = cars$dist)
plot(x = cars$dist, y = cars$speed)
plot(x = cars$speed, y = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(cars, main = "My Plot")
plot(cars, sub = "My Plot Subtitle")
plot(cars, col = 2)
plot(cars, xlim = c(10, 15))
plot(cars, pch = 2)
data(mtcars)
str(mtcars)
?boxplot
boxplot(mpg ~ cyl, data = mtcars)
hist(mtcars$mpg)
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",
destfile = "q1.csv",
method = "curl")
# read csv file
q1 <- read.csv("q1.csv", header = TRUE)
# load library
library(plyr)
library(dplyr)
# create a logical vector
q1 <- mutate(q1, agricultureLogical=factor((ACR == 3 & AGS == 6), levels = c(TRUE, FALSE)))
# show the first 3 row names which the logical value are TRUE
head(row.names(q1[which(q1$agricultureLogical == TRUE),]), 3)
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",
destfile = "q1.csv",
method = "curl")
q1 <- read.csv("q1.csv", header = TRUE)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
f <- file.path(getwd(), "jeff.jpg")
download.file(url, f, mode="wb")
img <- readJPEG(f, native=TRUE)
quantile(img, probs=c(0.3, 0.8))
gdpURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
eduURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
gdpFile <- tempfile()
eduFile <- tempfile()
download.file(gdpURL, gdpFile, method = "curl")
download.file(eduURL, eduFile, method = "curl")
gdprankings <- read.csv('getdata-data-GDP.csv', skip=4, stringsAsFactors = FALSE)
# Remove empty cols and ammend colnames
gdprankings[,3] <- gdprankings[,6] <- gdprankings[,7] <- gdprankings[,8] <- gdprankings[,9] <- gdprankings[,10]  <- NULL
colnames(gdprankings) <- c("abbreviation", "ranking", "economy", "gdp")
gdprankings <- gdprankings[gdprankings$abbreviation != "", ] # Remove entries w/ no abbreviation
gdprankings <- gdprankings[1:190,] ## Remove regions - just keep countries
gdprankings[,2] <- as.numeric(gdprankings[,2])
gdprankings[,4] <- gsub(",", "", gdprankings[,4]) # Remove "," to allow coercion
gdprankings[,4] <- as.integer(gdprankings[,4])
gdprankings <- gdprankings[order(gdp[,2]), ] ## Order by "gdp" descending
gdprankings[1:13,]
library(reshape2)
filename <- "getdata_dataset.zip"
if (!file.exists(filename)){
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip "
download.file(fileURL, filename, method="curl")
}
if (!file.exists(filename)){
+     fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
+     download.file(fileURL, filename, method="curl")
+ }
if (!file.exists(filename)){
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileURL, filename, method="curl")
}
XTrain <- XTest <- NULL
runAnalysis <- function() {
filePath <- function(...) { paste(..., sep = "/") }
downloadData <- function() {
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
downloadDir <- "data"
zipFile <- filePath(downloadDir, "dataset.zip")
if(!file.exists(zipFile)) { download.file(url, zipFile, method = "curl") }
dataDir <- "UCI HAR Dataset"
if(!file.exists(dataDir)) { unzip(zipFile, exdir = ".") }
dataDir
}
dataDir <- downloadData()
readData <- function(path) {
read.table(filePath(dataDir, path))
}
XTrain <- XTest <- NULL
runAnalysis <- function() {
# Get and extract data
filePath <- function(...) { paste(..., sep = "/") }
downloadData <- function() {
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
downloadDir <- "data"
zipFile <- filePath(downloadDir, "dataset.zip")
if(!file.exists(zipFile)) { download.file(url, zipFile, method = "curl") }
dataDir <- "UCI HAR Dataset"
if(!file.exists(dataDir)) { unzip(zipFile, exdir = ".") }
dataDir
}
dataDir <- downloadData()
# Merge the training and the test sets to create one data set.
readData <- function(path) {
read.table(filePath(dataDir, path))
}
# Read and cache XTrain and XTest data
if(is.null(XTrain)) { XTrain <<- readData("train/X_train.txt") }
if(is.null(XTest))  { XTest  <<- readData("test/X_test.txt") }
merged <- rbind(XTrain, XTest)
featureNames <- readData("features.txt")[, 2]
names(merged) <- featureNames
# Extract only the measurements on the mean and standard deviation for each measurement.
# Limit to columns with feature names matching mean() or std():
matches <- grep("(mean|std)\\(\\)", names(merged))
limited <- merged[, matches]
# Use descriptive activity names to name the activities in the data set.
# Get the activity data and map to nicer names:
yTrain <- read("train/y_train.txt")
yTest  <- read("test/y_test.txt")
yMerged <- rbind(yTrain, yTest)[, 1]
activityNames <-
c("Walking", "Walking Upstairs", "Walking Downstairs", "Sitting", "Standing", "Laying")
activities <- activityNames[yMerged]
# Appropriately label the data set with descriptive variable names.
# Change t to Time, f to Frequency, mean() to Mean and std() to StdDev
# Remove extra dashes and BodyBody naming error from original feature names
names(limited) <- gsub("^t", "Time", names(limited))
names(limited) <- gsub("^f", "Frequency", names(limited))
names(limited) <- gsub("-mean\\(\\)", "Mean", names(limited))
names(limited) <- gsub("-std\\(\\)", "StdDev", names(limited))
names(limited) <- gsub("-", "", names(limited))
names(limited) <- gsub("BodyBody", "Body", names(limited))
# Add activities and subject with nice names
subjectTrain <- read("train/subject_train.txt")
subjectTest  <- read("test/subject_test.txt")
subjects <- rbind(subjectTrain, subjectTest)[, 1]
tidy <- cbind(Subject = subjects, Activity = activities, limited)
# Create a second, independent tidy data set with the average of each variable for each activity and each subject.
library(plyr)
# Column means for all but the subject and activity columns
limitedColMeans <- function(data) { colMeans(data[,-c(1,2)]) }
tidyMeans <- ddply(tidy, .(Subject, Activity), limitedColMeans)
names(tidyMeans)[-c(1,2)] <- paste0("Mean", names(tidyMeans)[-c(1,2)])
# Write file
write.table(tidyMeans, "tidyMeans.txt", row.names = FALSE)
# Also return data
tidyMeans
}
# Use to check that the tidyMeans.txt is properly readable
checkData <- function() {
read.table("tidyMeans.txt", header = TRUE)
}
tidyMeans.txt
XTrain <- XTest <- NULL
runAnalysis <- function() {
# Get and extract data
filePath <- function(...) { paste(..., sep = "/") }
downloadData <- function() {
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
downloadDir <- "data"
zipFile <- filePath(downloadDir, "dataset.zip")
if(!file.exists(zipFile)) { download.file(url, zipFile, method = "curl") }
dataDir <- "UCI HAR Dataset"
if(!file.exists(dataDir)) { unzip(zipFile, exdir = ".") }
dataDir
}
dataDir <- downloadData()
# Merge the training and the test sets to create one data set.
readData <- function(path) {
read.table(filePath(dataDir, path))
}
# Read and cache XTrain and XTest data
if(is.null(XTrain)) { XTrain <<- readData("train/X_train.txt") }
if(is.null(XTest))  { XTest  <<- readData("test/X_test.txt") }
merged <- rbind(XTrain, XTest)
featureNames <- readData("features.txt")[, 2]
names(merged) <- featureNames
# Extract only the measurements on the mean and standard deviation for each measurement.
# Limit to columns with feature names matching mean() or std():
matches <- grep("(mean|std)\\(\\)", names(merged))
limited <- merged[, matches]
# Use descriptive activity names to name the activities in the data set.
# Get the activity data and map to nicer names:
yTrain <- read("train/y_train.txt")
yTest  <- read("test/y_test.txt")
yMerged <- rbind(yTrain, yTest)[, 1]
activityNames <-
c("Walking", "Walking Upstairs", "Walking Downstairs", "Sitting", "Standing", "Laying")
activities <- activityNames[yMerged]
# Appropriately label the data set with descriptive variable names.
# Change t to Time, f to Frequency, mean() to Mean and std() to StdDev
# Remove extra dashes and BodyBody naming error from original feature names
names(limited) <- gsub("^t", "Time", names(limited))
names(limited) <- gsub("^f", "Frequency", names(limited))
names(limited) <- gsub("-mean\\(\\)", "Mean", names(limited))
names(limited) <- gsub("-std\\(\\)", "StdDev", names(limited))
names(limited) <- gsub("-", "", names(limited))
names(limited) <- gsub("BodyBody", "Body", names(limited))
# Add activities and subject with nice names
subjectTrain <- read("train/subject_train.txt")
subjectTest  <- read("test/subject_test.txt")
subjects <- rbind(subjectTrain, subjectTest)[, 1]
tidy <- cbind(Subject = subjects, Activity = activities, limited)
# Create a second, independent tidy data set with the average of each variable for each activity and each subject.
library(plyr)
# Column means for all but the subject and activity columns
limitedColMeans <- function(data) { colMeans(data[,-c(1,2)]) }
tidyMeans <- ddply(tidy, .(Subject, Activity), limitedColMeans)
names(tidyMeans)[-c(1,2)] <- paste0("Mean", names(tidyMeans)[-c(1,2)])
# Write file
write.table(tidyMeans, "tidyMeans.txt", row.names = FALSE)
# Also return data
tidyMeans
}
# Use to check that the tidyMeans.txt is properly readable
checkData <- function() {
read.table("tidyMeans.txt", header = TRUE)
}
View(runAnalysis)
View(checkData)
View(runAnalysis)
install.packages("forecast")
install.packages(c("BH", "curl", "devtools", "digest", "evaluate", "git2r", "httr", "jsonlite", "lubridate", "memoise", "mime", "R6", "Rcpp", "RCurl", "roxygen2", "rstudioapi", "stringi", "swirl", "testthat", "tidyr", "xml2"))
install.packages(c("BH", "curl", "devtools", "digest", "evaluate",
library("assertthat", lib.loc="~/R/win-library/3.2")
library("BH", lib.loc="~/R/win-library/3.2")
library("bitops", lib.loc="~/R/win-library/3.2")
library("brew", lib.loc="~/R/win-library/3.2")
library("colorspace", lib.loc="~/R/win-library/3.2")
detach("package:colorspace", unload=TRUE)
detach("package:brew", unload=TRUE)
detach("package:bitops", unload=TRUE)
detach("package:BH", unload=TRUE)
detach("package:assertthat", unload=TRUE)
install.packages(c("BH", "curl", "devtools", "digest", "evaluate", "git2r", "httr", "jsonlite", "lubridate", "memoise", "mime", "R6", "Rcpp", "RCurl", "roxygen2", "rstudioapi", "stringi", "swirl", "testthat", "tidyr", "xml2"))
install.packages(c("BH", "curl", "devtools", "digest", "evaluate",
install.packages("knitr")
install.packages("knitrBootstrap")
install.packages(c("BH", "curl", "DBI", "devtools", "digest", "forecast", "git2r", "httr", "jsonlite", "lubridate", "memoise", "mime", "plotrix", "quantreg", "R6", "Rcpp", "RcppArmadillo", "RCurl", "roxygen2", "rstudioapi", "stringi", "swirl", "testthat", "tidyr", "tseries", "xml2", "zoo"))
install.packages(c("BH", "curl", "DBI", "devtools", "digest",
install.packages(c("BH", "curl", "DBI", "devtools", "digest", "forecast", "git2r", "httr", "jsonlite", "lubridate", "memoise", "mime", "plotrix", "quantreg", "R6", "Rcpp", "RcppArmadillo", "RCurl", "roxygen2", "rstudioapi", "stringi", "swirl", "testthat", "tidyr", "tseries", "xml2", "zoo"))
install.packages(c("BH", "curl", "DBI", "devtools", "digest", "forecast", "git2r", "httr", "jsonlite", "lubridate", "memoise", "mime", "plotrix", "quantreg", "R6", "Rcpp", "RcppArmadillo", "RCurl", "roxygen2", "rstudioapi", "stringi", "swirl", "testthat", "tidyr", "tseries", "xml2", "zoo"))
install.packages(c("BH", "curl", "DBI", "devtools", "digest",
install.packages(c("BH", "curl", "DBI", "devtools", "digest", "forecast", "git2r", "httr", "jsonlite", "lubridate", "memoise", "mime", "plotrix", "quantreg", "R6", "Rcpp", "RcppArmadillo", "RCurl", "roxygen2", "rstudioapi", "stringi", "swirl", "testthat", "tidyr", "tseries", "xml2", "zoo"))
install.packages(c("BH", "curl", "DBI", "devtools", "digest",
install.packages(c("BH", "curl", "DBI", "devtools", "digest", "forecast", "git2r", "httr", "jsonlite", "lubridate", "memoise", "mime", "plotrix", "quantreg", "R6", "Rcpp", "RcppArmadillo", "RCurl", "roxygen2", "rstudioapi", "stringi", "swirl", "testthat", "tidyr", "tseries", "xml2", "zoo"))
install.packages("evaluate")
text(x = -0.5,y=mean(Daytot$sum_steps),pos=1,labels = "mean")
setwd("~/Coursera/ReproducibleResearch/Week2/Week2/Assignment1/repdata_data_activity")
install.packages("markdown")
